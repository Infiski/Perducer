{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d49c57c-a078-48fe-982b-b88a26a36ea6",
   "metadata": {},
   "source": [
    "# R-Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8a8080-9905-4491-9bd5-f485513aec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811cb086-1307-47cf-9380-443eb1616689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a81e63-0993-4f5c-92dd-ab0f780519f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import RTier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f0db8-c592-456c-bbd8-48f675a8a268",
   "metadata": {},
   "source": [
    "## Logic of R-Cell Arbitrary Output Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc49d070-d3ca-492d-bae4-a66e5f405341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "batch_pos = torch.full((1, batch_size), 0)\n",
    "print(batch_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94f4bb4a-649f-4acc-bd7f-87a153cc2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(pos, dim):\n",
    "    # Convert pos to LongTensor (index tensor)\n",
    "    pos = pos.long()\n",
    "    # Use F.one_hot to perform one-hot encoding\n",
    "    return F.one_hot(pos, dim).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a8bd604-7c12-4c21-a2a1-f00bc4954d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "A tensor([[ 0.9976, -0.5279,  0.9949],\n",
      "        [ 0.0698, -0.1847,  0.9999]])\n",
      "B tensor([[ 0.9976,  0.4721,  0.9949],\n",
      "        [ 1.0698, -0.1847,  0.9999]])\n",
      "A tensor([[ 0.9976, -0.5279,  0.9949],\n",
      "        [ 0.0698, -0.1847,  0.9999]])\n",
      "B tensor([[0.9976, 0.4721, 0.9949],\n",
      "        [0.0698, 0.8153, 0.9999]])\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.9976, 0.4721, 0.9949],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0698, 0.8153, 0.9999]])\n",
      "tensor(True)\n",
      "h_next:\n",
      "tensor([[-0.7761, -1.1215,  0.7610, -0.0483],\n",
      "        [ 1.4732, -0.1821,  0.1879,  0.0521],\n",
      "        [ 0.4008, -0.3552,  2.3219,  1.2010],\n",
      "        [-0.6711,  0.1885,  0.0903,  0.5825],\n",
      "        [ 1.1357,  0.6900,  0.6549,  2.2198]])\n",
      "\n",
      "is_summ:\n",
      "tensor([False, False,  True, False,  True])\n",
      "\n",
      "r:\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.9976, 0.4721, 0.9949],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0698, 0.8153, 0.9999]])\n",
      "\n",
      "Batch Pos\n",
      "tensor([0, 0, 1, 0, 1], dtype=torch.int32)\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define dimensions\n",
    "batch_size = 5\n",
    "r_dim = 3\n",
    "h_dim = 4\n",
    "\n",
    "# Initialize h_next with some random values\n",
    "h_next = torch.randn(batch_size, h_dim)\n",
    "\n",
    "# Create a boolean mask is_summ\n",
    "is_summ = torch.tensor([False, False, True, False, True])\n",
    "batch_pos = torch.zeros(batch_size, dtype=torch.int)\n",
    "\n",
    "\n",
    "# Initialize r with zeros\n",
    "r = torch.zeros(batch_size, r_dim, device=h_next.device)\n",
    "\n",
    "# Define weight and bias for the linear transformation\n",
    "W_r = torch.randn(r_dim, h_dim)\n",
    "b_r = torch.randn(r_dim)\n",
    "\n",
    "# Compute r only for elements where is_summ is True\n",
    "true_indices = is_summ.nonzero(as_tuple=True)[0]\n",
    "print(r)\n",
    "for i in true_indices:\n",
    "    r[is_summ] = torch.tanh(F.linear(h_next[is_summ], W_r, b_r))\n",
    "    print(\"A\", r[is_summ])\n",
    "    batch_pos[i] += 1\n",
    "    one_hot_encoded = one_hot_encoding(batch_pos, r_dim)\n",
    "    r[is_summ] += one_hot_encoded[is_summ]\n",
    "\n",
    "    print(\"B\", r[is_summ])\n",
    "print(r)\n",
    "\n",
    "print(is_summ.any())\n",
    "# Print the results\n",
    "print(\"h_next:\")\n",
    "print(h_next)\n",
    "print(\"\\nis_summ:\")\n",
    "print(is_summ)\n",
    "print(\"\\nr:\")\n",
    "print(r)\n",
    "print(\"\\nBatch Pos\")\n",
    "print(batch_pos)\n",
    "\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a4d66-e207-4469-ad57-236e6fc4ad2a",
   "metadata": {},
   "source": [
    "## TEST 1 (Constant Embedding) <font color='green'>PASS</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea8a8765-c47a-40cf-9b92-9a964338a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "sequence_length = 20\n",
    "batch_size = 5\n",
    "\n",
    "behavior_dim = 2\n",
    "hidden_dim = 20\n",
    "run_dim = 32\n",
    "\n",
    "num_samples = 100\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# Corresponding to is_summ_flags create the y_data if is_summ_flag zero y_data should be zero otherwise 2\n",
    "y_data = 3 * torch.ones((num_samples, sequence_length, run_dim), dtype=torch.float32)\n",
    "\n",
    "# Initialize a boolean tensor with all False values\n",
    "is_summ_flags = torch.zeros((num_samples, sequence_length), dtype=torch.bool)\n",
    "\n",
    "# Iterate over each sample to set True values after the gap\n",
    "for i in range(num_samples):\n",
    "    idx = 0\n",
    "    \n",
    "    while idx < sequence_length:\n",
    "        gap = 2 + torch.randint(0, 6, (1,)).item()  # random number between 0 and 5\n",
    "        idx += gap\n",
    "        if idx < sequence_length:\n",
    "            is_summ_flags[i][idx] = True\n",
    "\n",
    "# Sample data creation\n",
    "b_data = torch.ones(num_samples, sequence_length, behavior_dim) + 9\n",
    "# Create y_data\n",
    "y_data = torch.zeros((num_samples, sequence_length, run_dim))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    for j in range(sequence_length):\n",
    "        if is_summ_flags[i][j]:\n",
    "            y_data[i][j] = torch.ones(run_dim) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6f75e2f-5302-4735-b0ac-77adb883412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.],\n",
       "        [10., 10.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a76ceab7-a0d1-4c8d-adea-559314a3da80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False, False, False, False, False,  True,\n",
       "        False, False, False, False, False,  True, False, False, False,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_summ_flags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94999c8d-e660-44e9-b63a-20fe42c2529b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73d2f632-c443-401b-b7da-68b480105654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.2148\n",
      "Epoch [2/100], Loss: 0.2010\n",
      "Epoch [3/100], Loss: 0.2010\n",
      "Epoch [4/100], Loss: 0.2010\n",
      "Epoch [5/100], Loss: 0.2010\n",
      "Epoch [6/100], Loss: 0.2010\n",
      "Epoch [7/100], Loss: 0.2010\n",
      "Epoch [8/100], Loss: 0.2010\n",
      "Epoch [9/100], Loss: 0.2010\n",
      "Epoch [10/100], Loss: 0.2010\n",
      "Epoch [11/100], Loss: 0.2010\n",
      "Epoch [12/100], Loss: 0.2010\n",
      "Epoch [13/100], Loss: 0.2010\n",
      "Epoch [14/100], Loss: 0.2010\n",
      "Epoch [15/100], Loss: 0.2010\n",
      "Epoch [16/100], Loss: 0.2010\n",
      "Epoch [17/100], Loss: 0.2010\n",
      "Epoch [18/100], Loss: 0.2010\n",
      "Epoch [19/100], Loss: 0.2010\n",
      "Epoch [20/100], Loss: 0.2010\n",
      "Epoch [21/100], Loss: 0.2010\n",
      "Epoch [22/100], Loss: 0.2010\n",
      "Epoch [23/100], Loss: 0.2010\n",
      "Epoch [24/100], Loss: 0.2010\n",
      "Epoch [25/100], Loss: 0.2010\n",
      "Epoch [26/100], Loss: 0.2010\n",
      "Epoch [27/100], Loss: 0.2010\n",
      "Epoch [28/100], Loss: 0.2010\n",
      "Epoch [29/100], Loss: 0.2010\n",
      "Epoch [30/100], Loss: 0.2010\n",
      "Epoch [31/100], Loss: 0.2010\n",
      "Epoch [32/100], Loss: 0.2010\n",
      "Epoch [33/100], Loss: 0.2010\n",
      "Epoch [34/100], Loss: 0.2010\n",
      "Epoch [35/100], Loss: 0.2010\n",
      "Epoch [36/100], Loss: 0.2010\n",
      "Epoch [37/100], Loss: 0.2010\n",
      "Epoch [38/100], Loss: 0.2010\n",
      "Epoch [39/100], Loss: 0.2010\n",
      "Epoch [40/100], Loss: 0.2010\n",
      "Epoch [41/100], Loss: 0.2010\n",
      "Epoch [42/100], Loss: 0.2010\n",
      "Epoch [43/100], Loss: 0.2010\n",
      "Epoch [44/100], Loss: 0.2010\n",
      "Epoch [45/100], Loss: 0.2010\n",
      "Epoch [46/100], Loss: 0.2010\n",
      "Epoch [47/100], Loss: 0.2010\n",
      "Epoch [48/100], Loss: 0.2010\n",
      "Epoch [49/100], Loss: 0.2010\n",
      "Epoch [50/100], Loss: 0.2010\n",
      "Epoch [51/100], Loss: 0.2010\n",
      "Epoch [52/100], Loss: 0.2010\n",
      "Epoch [53/100], Loss: 0.2010\n",
      "Epoch [54/100], Loss: 0.2010\n",
      "Epoch [55/100], Loss: 0.2010\n",
      "Epoch [56/100], Loss: 0.2010\n",
      "Epoch [57/100], Loss: 0.2010\n",
      "Epoch [58/100], Loss: 0.2010\n",
      "Epoch [59/100], Loss: 0.2010\n",
      "Epoch [60/100], Loss: 0.2010\n",
      "Epoch [61/100], Loss: 0.2010\n",
      "Epoch [62/100], Loss: 0.2010\n",
      "Epoch [63/100], Loss: 0.2010\n",
      "Epoch [64/100], Loss: 0.2010\n",
      "Epoch [65/100], Loss: 0.2010\n",
      "Epoch [66/100], Loss: 0.2010\n",
      "Epoch [67/100], Loss: 0.2010\n",
      "Epoch [68/100], Loss: 0.2010\n",
      "Epoch [69/100], Loss: 0.2010\n",
      "Epoch [70/100], Loss: 0.2010\n",
      "Epoch [71/100], Loss: 0.2010\n",
      "Epoch [72/100], Loss: 0.2010\n",
      "Epoch [73/100], Loss: 0.2010\n",
      "Epoch [74/100], Loss: 0.2010\n",
      "Epoch [75/100], Loss: 0.2010\n",
      "Epoch [76/100], Loss: 0.2010\n",
      "Epoch [77/100], Loss: 0.2010\n",
      "Epoch [78/100], Loss: 0.2010\n",
      "Epoch [79/100], Loss: 0.2010\n",
      "Epoch [80/100], Loss: 0.2010\n",
      "Epoch [81/100], Loss: 0.2010\n",
      "Epoch [82/100], Loss: 0.2010\n",
      "Epoch [83/100], Loss: 0.2010\n",
      "Epoch [84/100], Loss: 0.2010\n",
      "Epoch [85/100], Loss: 0.2010\n",
      "Epoch [86/100], Loss: 0.2010\n",
      "Epoch [87/100], Loss: 0.2010\n",
      "Epoch [88/100], Loss: 0.2010\n",
      "Epoch [89/100], Loss: 0.2010\n",
      "Epoch [90/100], Loss: 0.2010\n",
      "Epoch [91/100], Loss: 0.2010\n",
      "Epoch [92/100], Loss: 0.2010\n",
      "Epoch [93/100], Loss: 0.2010\n",
      "Epoch [94/100], Loss: 0.2010\n",
      "Epoch [95/100], Loss: 0.2010\n",
      "Epoch [96/100], Loss: 0.2010\n",
      "Epoch [97/100], Loss: 0.2010\n",
      "Epoch [98/100], Loss: 0.2010\n",
      "Epoch [99/100], Loss: 0.2010\n",
      "Epoch [100/100], Loss: 0.2010\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(b_data, is_summ_flags, y_data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model instantiation\n",
    "model = RTier(behavior_dim, hidden_dim, run_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        b_data, is_summ_flags, y_data = batch\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model((b_data, is_summ_flags, y_data))\n",
    "        loss = criterion(output, y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354eb66e-fd9c-44e8-9511-389cf65211e1",
   "metadata": {},
   "source": [
    "##### One-Hot Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c4aba0-494a-4d04-965f-4a49d6816689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5048d55a-bd2b-4e44-8899-2264f914ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "embedding_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17927753-eb6d-44c9-9778-41b135fac06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.randn(batch_size, seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711f5ea3-a0f5-4ad7-bd98-6131590214de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0240,  1.6658,  0.1412, -1.5008, -0.5063, -0.7110,  1.4140,\n",
       "          -0.0741],\n",
       "         [-0.0411, -1.0450,  0.0989, -0.4587, -0.4409,  0.6957, -1.1044,\n",
       "           0.7425],\n",
       "         [-1.1492, -0.0069,  0.6731, -0.2991, -0.0801, -0.7374,  0.2929,\n",
       "           1.8192],\n",
       "         [ 0.7640,  1.0874, -0.2307, -0.8909, -0.1001,  0.7470,  0.0487,\n",
       "          -0.7188],\n",
       "         [-1.4021,  0.5715, -0.4163,  1.0333,  1.9638, -1.0180, -0.2020,\n",
       "          -0.2069],\n",
       "         [-0.0415,  0.9216, -0.9418, -0.4767,  0.7513,  1.6361,  1.3862,\n",
       "           0.8791],\n",
       "         [ 0.1723, -1.3469,  0.5914, -0.3936,  1.5920,  0.3846, -0.3332,\n",
       "          -1.4006],\n",
       "         [-1.9345,  0.0978, -0.0318, -1.6688, -0.6154, -1.1919, -0.5048,\n",
       "           0.5712],\n",
       "         [-0.5017, -0.6525,  1.5569, -0.5583, -0.0602,  1.6316, -0.2350,\n",
       "          -0.3422],\n",
       "         [ 0.9003, -0.2596, -0.1510,  0.3825,  0.9566, -1.1434,  1.3284,\n",
       "          -0.7951]],\n",
       "\n",
       "        [[ 1.4585, -1.6691, -1.8006, -0.6093, -0.5736, -0.2863, -1.3630,\n",
       "           1.9419],\n",
       "         [ 0.3059,  0.5304, -0.1557,  0.5288,  0.5114, -0.9285,  0.3606,\n",
       "          -2.8261],\n",
       "         [ 2.5945,  0.5861, -0.1883,  0.7354,  0.4757, -0.1022, -1.0818,\n",
       "          -0.4982],\n",
       "         [-0.3529,  0.3698, -1.4443, -1.2743,  0.1676,  0.2362,  1.6031,\n",
       "          -0.2606],\n",
       "         [ 0.0427, -0.8988, -0.8710,  0.7149, -1.8504, -0.6263, -0.4881,\n",
       "          -0.1064],\n",
       "         [-0.3106, -1.7875,  0.2902, -0.3734,  0.0139, -0.1070,  0.3635,\n",
       "           0.0273],\n",
       "         [-0.0837, -0.3995,  2.2727, -1.8226,  0.1064,  0.6177,  0.2573,\n",
       "          -0.1714],\n",
       "         [-0.7335, -0.9101, -2.3458,  1.3569, -1.2772,  0.3160,  0.8493,\n",
       "          -0.2406],\n",
       "         [ 0.8952, -1.4299,  0.6301, -0.2475, -0.4242,  0.4805,  0.1658,\n",
       "           0.0239],\n",
       "         [-0.3909, -1.2610,  0.5399,  0.6421, -1.1821,  0.9507, -2.3732,\n",
       "          -0.7831]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf285e27-fb0c-4fc9-bc71-7905ea6c68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "one_hot_positional_encodings = F.one_hot(position_ids, num_classes=seq_len).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc956d66-84fa-49ba-8aa0-a9e60b8b85a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_positional_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8520dd27-1d89-45b8-a41d-63853d931782",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mone_hot_positional_encodings\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "combined_embeddings = embeddings + one_hot_positional_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "113bb9f8-e864-4913-8bab-ec0af3f165a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([2, 5, 8])\n",
      "One-hot positional encodings shape: torch.Size([2, 5, 8])\n",
      "Combined embeddings shape: torch.Size([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Parameters\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "embedding_dim = 8\n",
    "\n",
    "# Step 1: Create random embeddings\n",
    "embeddings = torch.randn(batch_size, seq_len, embedding_dim)\n",
    "\n",
    "# Step 2: Create one-hot positional encodings\n",
    "position_ids = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "one_hot_positional_encodings = F.one_hot(position_ids, num_classes=seq_len).float()\n",
    "\n",
    "# Step 3: Interpolate the one-hot encodings to match the embedding dimension\n",
    "# Add a dummy dimension to use interpolate and then remove it\n",
    "one_hot_positional_encodings = one_hot_positional_encodings.unsqueeze(1)  # Shape: (batch_size, 1, seq_len, seq_len)\n",
    "one_hot_positional_encodings = F.interpolate(one_hot_positional_encodings, size=(seq_len, embedding_dim), mode='bilinear', align_corners=False)\n",
    "one_hot_positional_encodings = one_hot_positional_encodings.squeeze(1)  # Shape: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "# Step 4: Combine embeddings with positional encodings\n",
    "combined_embeddings = embeddings + one_hot_positional_encodings\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"One-hot positional encodings shape: {one_hot_positional_encodings.shape}\")\n",
    "print(f\"Combined embeddings shape: {combined_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81c62825-134b-4139-9b2d-790571570362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0599,  0.4645,  0.5465, -1.0917,  0.0642,  0.6623,  0.6286,\n",
       "          -0.8372],\n",
       "         [ 0.0327,  0.6828,  1.2170,  0.2863,  0.1587,  0.5921,  0.0660,\n",
       "          -0.7419],\n",
       "         [ 0.8163, -1.0227,  0.2353, -0.8698, -0.6066,  0.8241,  1.3457,\n",
       "          -1.2792],\n",
       "         [ 1.6519, -0.8593, -1.0126,  0.0833,  1.0629, -0.7051, -1.0721,\n",
       "          -0.5183],\n",
       "         [ 0.3135,  1.4274, -0.2910,  0.0282, -1.4946, -1.2530, -1.1248,\n",
       "          -1.0686]],\n",
       "\n",
       "        [[-0.6167, -0.6189, -3.1582, -0.3099, -0.3236,  0.4801,  0.0295,\n",
       "           0.0938],\n",
       "         [-1.3505,  0.6629,  0.5287,  0.9935,  0.3090,  0.1417,  1.1674,\n",
       "          -0.5419],\n",
       "         [ 0.0799,  1.6759, -0.6971, -1.8678,  1.3571,  0.2774, -0.1568,\n",
       "          -0.7590],\n",
       "         [-1.5802, -0.8637, -0.1351,  0.7873,  1.7351, -0.1225, -1.1544,\n",
       "           0.1233],\n",
       "         [ 0.0084,  1.8210,  1.0898, -0.4848,  0.2294, -0.6013, -0.8195,\n",
       "          -0.3167]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ad54e3-0bba-4a99-8940-488ef2d176db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.5625, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.4375, 0.9375, 0.3125, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0625, 0.6875, 0.6875, 0.0625, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.9375, 0.4375, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5625, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.5625, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.4375, 0.9375, 0.3125, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0625, 0.6875, 0.6875, 0.0625, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3125, 0.9375, 0.4375, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5625, 1.0000]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_positional_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15f25a36-2c9d-4868-8d03-2653b76c9aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf661725-6ce5-4b46-a879-f0cc065df1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1d9010-4af3-442e-ab56-da0fc63ac399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4, 4, 4, 4]])\n",
      "tensor([[[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def one_hot_encoding(pos, dim):\n",
    "    return F.one_hot(pos, dim).float()\n",
    "\n",
    "# Test the function with dummy input\n",
    "\n",
    "pos = 4\n",
    "batch = 5\n",
    "pos = torch.full((1, batch), pos)\n",
    "print(pos)\n",
    "dim = 9\n",
    "one_hot_encoded = one_hot_encoding(pos, dim)\n",
    "\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cdc203-65a9-49dd-a596-4d71dbc6f4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7, 7],\n",
      "        [7, 7, 7, 7],\n",
      "        [7, 7, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282558f7-ab2a-4e48-b8fa-e9a2bb7ed07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
